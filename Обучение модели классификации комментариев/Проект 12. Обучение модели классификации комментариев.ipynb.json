{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис, который позволяет пользователям редактировать и дополнять описания товаров, аналогично вики-сообществам. Но при таком подходе возникает проблема токсичных комментариев и правок.\n",
    "\n",
    "Для решения этой проблемы компания нуждается в инструменте, который автоматически будет выполнять задачу модерации комментариев, выявляя токсичные и отправляя их на дополнительную проверку и обработку. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.9/site-packages (3.2.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.21.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.7.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.4.4)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy) (49.6.0.post20210108)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (4.61.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /opt/conda/lib/python3.9/site-packages (from spacy) (8.0.17)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy) (2.1.1)\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from en-core-web-sm==3.2.0) (3.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.25.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.61.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.8)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.10.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.17)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.21.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2022.6.15)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import re\n",
    "from pymystem3 import Mystem \n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('wordnet')\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m spacy download en\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv(r'/Users/arina200212yandex.ru/Desktop/toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv(r'/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для повышения качества анализа текстовых данных требуется выполнить их предварительную обработку. Две важные операции, которые следует провести, - лемматизация и удаление разделителей строк и заглавных символов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z ]+\", \"\", text).strip()\n",
    "    text = text.lower()\n",
    "    return \" \".join(text.split())\n",
    "data['text'] = data['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanationwhy the edits made under my usernam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hey man im really not trying to edit war its j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>morei cant make any real suggestions on improv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>and for the second time of asking when your vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>you should be ashamed of yourself that is a ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>and it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>and i really dont think you understand i came ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  explanationwhy the edits made under my usernam...      0\n",
       "1                1  daww he matches this background colour im seem...      0\n",
       "2                2  hey man im really not trying to edit war its j...      0\n",
       "3                3  morei cant make any real suggestions on improv...      0\n",
       "4                4  you sir are my hero any chance you remember wh...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  and for the second time of asking when your vi...      0\n",
       "159288      159447  you should be ashamed of yourself that is a ho...      0\n",
       "159289      159448  spitzer umm theres no actual article for prost...      0\n",
       "159290      159449  and it looks like it was actually you who put ...      0\n",
       "159291      159450  and i really dont think you understand i came ...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return  \" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159292/159292 [19:20<00:00, 137.22it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "data['lemm_text'] = data['text'].progress_apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemm_text'] = data['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим старый столбец с текстом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanationwhy the edit make under my username...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>daww he match this background colour I m seemi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man I m really not try to edit war its jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>morei can not make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of ask when your view ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that be a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm there s no actual article for pros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>0</td>\n",
       "      <td>and it look like it be actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>0</td>\n",
       "      <td>and I really do not think you understand I com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  toxic                                          lemm_text\n",
       "0                0      0  explanationwhy the edit make under my username...\n",
       "1                1      0  daww he match this background colour I m seemi...\n",
       "2                2      0  hey man I m really not try to edit war its jus...\n",
       "3                3      0  morei can not make any real suggestion on impr...\n",
       "4                4      0  you sir be my hero any chance you remember wha...\n",
       "...            ...    ...                                                ...\n",
       "159287      159446      0  and for the second time of ask when your view ...\n",
       "159288      159447      0  you should be ashamed of yourself that be a ho...\n",
       "159289      159448      0  spitzer umm there s no actual article for pros...\n",
       "159290      159449      0  and it look like it be actually you who put on...\n",
       "159291      159450      0  and I really do not think you understand I com...\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После предварительной обработки текстовых данных, необходимо разделить их на обучающую, тестовую и валидационную выборки. Далее, для каждого слова в текстах следует вычислить его вес TF-IDF. После этого можно будет приступать к обучению моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['toxic'].values\n",
    "features = data['lemm_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(features,target,test_size=0.5,random_state=1515)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid,target_valid,test_size=0.5,random_state=1515)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = count_tf_idf.fit_transform(features_train)\n",
    "tfidf_valid = count_tf_idf.transform(features_valid)\n",
    "tfidf_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведена предварительная обработка текстовых данных, включающая лемматизацию и удаление разделителей строк и заглавных символов. \n",
    "Далее данные были разбиты на обучающую, тестовую и валидационную выборки. \n",
    "После этого для каждого слова в текстах было сделано TF-IDF. Данные готовы к использованию в обучении моделей машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения задачи классификации текстов будут обучены три модели: дерево решений, случайный лес и логистическая регрессия. \n",
    "\n",
    "Далее будет проведено сравнение значений метрики F1 для каждой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Глубина дерева: 1 0.2751790981879477\n",
      "Глубина дерева: 2 0.36261980830670926\n",
      "Глубина дерева: 3 0.41800766283524904\n",
      "Глубина дерева: 4 0.46068042387060787\n",
      "Глубина дерева: 5 0.49365050974780894\n",
      "Глубина дерева: 6 0.5231521929058186\n",
      "Глубина дерева: 7 0.5507345404851384\n",
      "Глубина дерева: 8 0.5653865674166808\n",
      "Глубина дерева: 9 0.5816053511705686\n",
      "Глубина дерева: 10 0.5924327912379688\n",
      "Глубина дерева: 11 0.60238211780062\n",
      "Глубина дерева: 12 0.6129501049572098\n",
      "Глубина дерева: 13 0.6169557464743071\n",
      "Глубина дерева: 14 0.6224701195219124\n",
      "Глубина дерева: 15 0.620147577799166\n",
      "Глубина дерева: 16 0.6278553299492386\n",
      "Глубина дерева: 17 0.6326402016383113\n",
      "Глубина дерева: 18 0.6380848067595056\n",
      "Глубина дерева: 19 0.6433328170977234\n",
      "Глубина дерева: 20 0.6477607314427398\n",
      "Глубина дерева: 21 0.6520270270270271\n",
      "Глубина дерева: 22 0.6510408635312259\n",
      "Глубина дерева: 23 0.6546795758414016\n",
      "Глубина дерева: 24 0.6576645695872334\n",
      "Глубина дерева: 25 0.6624357812027803\n",
      "Глубина дерева: 26 0.6628398791540786\n",
      "Глубина дерева: 27 0.6674677080204265\n",
      "Глубина дерева: 28 0.6700675168792197\n",
      "Глубина дерева: 29 0.6682606096832038\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1,30):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=1234)\n",
    "    model.fit(tfidf_train,target_train)\n",
    "    predictions = model.predict(tfidf_valid)\n",
    "    f1 = f1_score(predictions, target_valid)\n",
    "    print(\"Глубина дерева:\", depth, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1 max_iter: 1 0.6225322142097174\n",
      "C: 1 max_iter: 101 0.7639569049951028\n",
      "C: 1 max_iter: 201 0.7639569049951028\n",
      "C: 2 max_iter: 1 0.6086065573770492\n",
      "C: 2 max_iter: 101 0.7750817884405671\n",
      "C: 2 max_iter: 201 0.7750817884405671\n",
      "C: 3 max_iter: 1 0.598999444135631\n",
      "C: 3 max_iter: 101 0.7777027938993116\n",
      "C: 3 max_iter: 201 0.7777027938993116\n",
      "C: 4 max_iter: 1 0.5875533194793832\n",
      "C: 4 max_iter: 101 0.7757185065807143\n",
      "C: 4 max_iter: 201 0.7757185065807143\n",
      "C: 5 max_iter: 1 0.5791238507301244\n",
      "C: 5 max_iter: 101 0.7732869379014989\n",
      "C: 5 max_iter: 201 0.7732869379014989\n",
      "C: 6 max_iter: 1 0.5727487642381259\n",
      "C: 6 max_iter: 101 0.7725150100066711\n",
      "C: 6 max_iter: 201 0.7725150100066711\n",
      "C: 7 max_iter: 1 0.565068493150685\n",
      "C: 7 max_iter: 101 0.7708887706226716\n",
      "C: 7 max_iter: 201 0.7708887706226716\n",
      "C: 8 max_iter: 1 0.560887182768181\n",
      "C: 8 max_iter: 101 0.7689650591204995\n",
      "C: 8 max_iter: 201 0.7689650591204995\n",
      "C: 9 max_iter: 1 0.556687898089172\n",
      "C: 9 max_iter: 101 0.7668874172185429\n",
      "C: 9 max_iter: 201 0.7668874172185429\n"
     ]
    }
   ],
   "source": [
    "for c in range(1,10):\n",
    "    for itery in range(1,300,100):\n",
    "        model = model = LogisticRegression(random_state=12345, C = c, penalty = 'l1', solver='liblinear', max_iter=itery)\n",
    "        model.fit(tfidf_train,target_train)\n",
    "        predictions = model.predict(tfidf_valid)\n",
    "        f1 = f1_score(predictions, target_valid)\n",
    "        print(\"C:\",c,\"max_iter:\",itery, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После обучения и сравнения трех моделей машинного обучения - дерева решений, случайного леса и логистической регрессии - был получен лучший результат. \n",
    "\n",
    "Лучшая модель была определена как логистическая регрессия с параметрами С: 3 и max_iter: 101, которая показала значение метрики F1 равное 0.7725797728501892.\n",
    "\n",
    "Таким образом, лучшей и наиболее подходящей моделью для данной задачи классификации текстов оказалась линейная регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7741141058968396"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, C = 3, penalty = 'l1', solver='liblinear', max_iter= 101)\n",
    "model.fit(tfidf_train,target_train)\n",
    "predictions  = model.predict(tfidf_test)\n",
    "f1_score(target_test, predictions )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате предварительной обработки текстовых данных и обучения моделей машинного обучения была достигнута метрика F1 выше 0.75 на тестовой выборке.\n",
    "\n",
    "Наилучшей моделью для данной задачи оказалась линейная регрессия с определенными гиперпараметрами: random_state=12345, C = 3, penalty = 'l1', solver='liblinear', max_iter= 101. Это помогло достичь высокого значения метрики F1."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2656,
    "start_time": "2023-04-04T06:07:50.241Z"
   },
   {
    "duration": 2980,
    "start_time": "2023-04-04T06:07:52.900Z"
   },
   {
    "duration": 13,
    "start_time": "2023-04-04T06:07:55.882Z"
   },
   {
    "duration": 1850,
    "start_time": "2023-04-04T06:07:55.896Z"
   },
   {
    "duration": 7,
    "start_time": "2023-04-04T06:07:57.747Z"
   },
   {
    "duration": 731,
    "start_time": "2023-04-04T06:07:57.755Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-04T06:07:58.488Z"
   },
   {
    "duration": 18169,
    "start_time": "2023-04-05T18:53:42.280Z"
   },
   {
    "duration": 3475,
    "start_time": "2023-04-05T18:54:00.452Z"
   },
   {
    "duration": 18,
    "start_time": "2023-04-05T18:54:03.929Z"
   },
   {
    "duration": 2783,
    "start_time": "2023-04-05T18:54:03.949Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-05T18:54:06.734Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-05T18:54:06.747Z"
   },
   {
    "duration": 1160832,
    "start_time": "2023-04-05T18:54:06.752Z"
   },
   {
    "duration": 27,
    "start_time": "2023-04-05T19:13:27.586Z"
   },
   {
    "duration": 17167,
    "start_time": "2023-04-06T06:25:15.081Z"
   },
   {
    "duration": 3197,
    "start_time": "2023-04-06T06:25:36.236Z"
   },
   {
    "duration": 13,
    "start_time": "2023-04-06T06:25:39.435Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-06T06:28:40.399Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-06T06:28:40.401Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-06T06:28:43.774Z"
   },
   {
    "duration": 5299,
    "start_time": "2023-04-06T06:29:18.909Z"
   },
   {
    "duration": 11010,
    "start_time": "2023-04-06T06:29:35.595Z"
   },
   {
    "duration": 844,
    "start_time": "2023-04-06T06:29:46.607Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-06T06:29:47.452Z"
   },
   {
    "duration": 2502,
    "start_time": "2023-04-06T06:29:47.464Z"
   },
   {
    "duration": 11,
    "start_time": "2023-04-06T06:29:49.969Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-06T06:29:49.982Z"
   },
   {
    "duration": 998167,
    "start_time": "2023-04-06T06:29:49.989Z"
   },
   {
    "duration": 36,
    "start_time": "2023-04-06T06:47:17.225Z"
   },
   {
    "duration": 10,
    "start_time": "2023-04-06T06:47:18.079Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-06T06:47:23.678Z"
   },
   {
    "duration": 50,
    "start_time": "2023-04-06T06:47:24.443Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-06T06:47:25.720Z"
   },
   {
    "duration": 7049,
    "start_time": "2023-04-06T06:47:28.183Z"
   },
   {
    "duration": 163669,
    "start_time": "2023-04-06T06:47:45.937Z"
   },
   {
    "duration": 103162,
    "start_time": "2023-04-06T06:50:56.769Z"
   },
   {
    "duration": 1147,
    "start_time": "2023-04-06T06:53:14.161Z"
   },
   {
    "duration": 49,
    "start_time": "2023-04-06T06:53:55.480Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
